[
    {
        "test_name": "llama8B_tp1_sharegpt",
        "qps_list": [1, 16],
        "lmdeploy_server_model": "meta-llama/Llama-2-7b-hf",
        "lmdeploy_server_parameters": {
            "tp": 1,
            "server_port": 8000
        },
        "lmdeploy_client_parameters": {
            "model": "llama2",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200,
            "port": 8000
        },
        "tgi_server_parameters": {
            "model_id": "meta-llama/Llama-2-7b-hf",
            "num_shard": 1,
            "port": 8000
        },
        "tgi_client_parameters": {
            "model": "meta-llama/Llama-2-7b-hf",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200,
            "port": 8000,
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_path": "meta-llama/llama-2-7b-chat-hf",
            "model_name": "llama-2-7b-chat-hf",
            "model_type": "llama",
            "model_dtype": "float16",
            "model_tp_size": 1,
            "max_batch_size": 256,
            "max_input_len": 10000,
            "max_output_len": 10000
        },
        "trt_client_parameters": {
            "model": "meta-llama/Llama-2-7b-hf",
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 200,
            "port": 8000,
            "endpoint": "/v2/models/ensemble/generate_stream"
        }
    }
]